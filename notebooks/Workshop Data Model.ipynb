{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58a13fc0",
   "metadata": {},
   "source": [
    "# Foodie Recommender Data Model (V0.1)\n",
    "We'll choose a set of starter features and attempt to train a two-towered recommender system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b7cb29",
   "metadata": {},
   "source": [
    "## Data Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24be2c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dateutil\n",
    "from pydantic import BaseModel, validator\n",
    "import os\n",
    "from typing import Any, List\n",
    "\n",
    "import json\n",
    "\n",
    "\n",
    "genres = {}\n",
    "\n",
    "\n",
    "\n",
    "def save_model_data(model: BaseModel, filename: str) -> str:\n",
    "    with open(filename, 'w+') as file:\n",
    "        json.dump(model.json(), file)\n",
    "    return filename\n",
    "\n",
    "\n",
    "\n",
    "def create_empty_genres_file(filepath: str) -> None:\n",
    "    with open(filepath, 'w+') as file:\n",
    "        json.dump({}, file)\n",
    "    return {}\n",
    "        \n",
    "        \n",
    "\n",
    "def load_or_create_genres(genres_file='genres.json') -> dict:\n",
    "    if os.path.isfile(genres_file):\n",
    "        with open(genres_file, 'r') as file:\n",
    "            return json.load(file)\n",
    "    else:\n",
    "        print('file not found', genres_file)\n",
    "        return create_empty_genres_file(genres_file)\n",
    "\n",
    "\n",
    "    \n",
    "def save_genres(genres: dict, genres_file='genres.json') -> dict:\n",
    "    with open(genres_file, 'w+') as file:\n",
    "        json.dump(genres, file)\n",
    "    return genres\n",
    "\n",
    "    \n",
    "        \n",
    "def add_element_to_genres(element: str) -> int:\n",
    "    genres = load_or_create_genres()\n",
    "    dict_len = len(genres)\n",
    "    if element not in genres:\n",
    "        genres[element] = dict_len + 1\n",
    "        genres = save_genres(genres)\n",
    "    return genres[element]\n",
    "        \n",
    "        \n",
    "        \n",
    "def map_genre(genre_list: list) -> list:\n",
    "    tmp = []\n",
    "    for element in genre_list:\n",
    "        tmp.append(add_element_to_genres(element))\n",
    "    return tmp\n",
    "        \n",
    "\n",
    "    \n",
    "class RestaurantUser(BaseModel):\n",
    "    user_birth_date: int\n",
    "    user_genres: List[Any] = [0]\n",
    "    user_id: int\n",
    "    user_occupation: str\n",
    "    user_gender: bool  # 0: male, 1: female\n",
    "    user_zip_code: int\n",
    "    \n",
    "    \n",
    "    @validator('user_genres')\n",
    "    def index_or_add(cls, v):\n",
    "        assert len(v) > 0, 'Must provide list of genre > 0'\n",
    "        return map_genre(v)\n",
    "    \n",
    "    def save(self, prefix='user') -> None:\n",
    "        name = prefix + f\"_{self.user_id}.json\"\n",
    "        return save_model_data(self, name)\n",
    "\n",
    "    \n",
    "        \n",
    "class Restaurant(BaseModel):\n",
    "    restaurant_id: int\n",
    "    restaurant_title: str\n",
    "    restaurant_genres: List[Any]\n",
    "    restaurant_zip_code: int\n",
    "   \n",
    "    @validator('restaurant_genres')\n",
    "    def index_or_add(cls, v):\n",
    "        assert len(v) > 0, 'Must provide list of genre > 0'\n",
    "        return map_genre(v)\n",
    "        \n",
    "    def save(self, prefix='restaurant') -> str:\n",
    "        name = prefix + f\"_{self.restaurant_id}.json\"\n",
    "        return save_model_data(self, name)\n",
    "    \n",
    "    \n",
    "    \n",
    "class RestaurantRating(BaseModel):\n",
    "    user: RestaurantUser\n",
    "    restaurant: Restaurant\n",
    "    timestamp: int  # Converting all date/time to posix integer\n",
    "    restaurant_rating: int\n",
    "    \n",
    "    @validator('timestamp')\n",
    "    def convert_valid_time(cls, v: str):\n",
    "        return v\n",
    "    \n",
    "    def save(self, prefix='rating') -> str:\n",
    "        name = prefix + f\"_{self.restaurant}_{self.user}_{self.timestamp}.json\"\n",
    "        return save_model_data(self, name)\n",
    "    \n",
    "    def flatten(self) -> dict:\n",
    "        tmp = {\n",
    "            **self.user.dict(), **self.restaurant.dict(),\n",
    "            'timestamp': self.timestamp,\n",
    "            'restaurant_rating': self.restaurant_rating,\n",
    "        }\n",
    "        return tmp\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "106f9247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test user\n",
    "user_profile = {\n",
    "    \"user_birth_date\": 20220101,\n",
    "    \"user_genres\": ['vegetarian', 'thai'],\n",
    "    \"user_id\": 1001,\n",
    "    \"user_occupation\": \"student\",\n",
    "    \"user_gender\": 0,  # 0: male, 1: female\n",
    "    \"user_zip_code\": 84104,\n",
    "}\n",
    "\n",
    "user = RestaurantUser(**user_profile)\n",
    "\n",
    "# Create a test restaurant\n",
    "restaurant_profile = {\n",
    "    \"restaurant_id\": 1,\n",
    "    \"restaurant_title\": \"skinnyfats\",\n",
    "    \"restaurant_genres\": ['vegetarian', 'thai', 'healthy', 'fried'],\n",
    "    \"restaurant_zip_code\": 84104,\n",
    "}\n",
    "\n",
    "restaurant = Restaurant(**restaurant_profile)\n",
    "\n",
    "# Create a test rating\n",
    "rating_profile = {\n",
    "    \"user\": user,\n",
    "    \"restaurant\": restaurant,\n",
    "    \"timestamp\": 202201012200,  # Converting all date/time to posix integer\n",
    "    \"restaurant_rating\": 10,\n",
    "}\n",
    "\n",
    "rating = RestaurantRating(**rating_profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "004c7e56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_birth_date': 20220101,\n",
       " 'user_genres': [1, 2],\n",
       " 'user_id': 1001,\n",
       " 'user_occupation': 'student',\n",
       " 'user_gender': False,\n",
       " 'user_zip_code': 84104,\n",
       " 'restaurant_id': 1,\n",
       " 'restaurant_title': 'skinnyfats',\n",
       " 'restaurant_genres': [1, 2, 3, 4],\n",
       " 'restaurant_zip_code': 84104,\n",
       " 'timestamp': 202201012200,\n",
       " 'restaurant_rating': 10}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The rating object contains user and restaurant models \n",
    "# Here, we implement a helper fn flatten to make it an easier document to deal with\n",
    "rating.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60444f0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_birth_date': 20220101,\n",
       " 'user_genres': [1, 2],\n",
       " 'user_id': 1001,\n",
       " 'user_occupation': 'student',\n",
       " 'user_gender': False,\n",
       " 'user_zip_code': 84104}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our user model can output a dictionary as well with a direct call to the dict() method\n",
    "user.dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a35e82",
   "metadata": {},
   "source": [
    "## Convert to Tensorflow Dataset\n",
    "We'll now arbitrarily copy the data and create Tensorflow datasets to train new embeddigns models with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07b8531e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc08d79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll convert the dict values to np arrays first\n",
    "\n",
    "def values_to_array(input_dict: dict) -> np.array:\n",
    "    tmp = {}\n",
    "    for key in input_dict:\n",
    "        tmp[key] = np.array([input_dict[key]])\n",
    "    return tmp\n",
    "\n",
    "# Once the data is in array format, elementwise concatenation will emulate a row\n",
    "def concatenate_dicts(dicts: List[dict]) -> dict:\n",
    "    \n",
    "    def _fetch_values(dicts: list, key: str) -> list:\n",
    "        return tuple([d[key] for d in dicts])\n",
    "    \n",
    "    parent = dicts[0]\n",
    "    tmp = {}\n",
    "    for key in parent:\n",
    "        tmp[key] = np.concatenate(_fetch_values(dicts, key))\n",
    "    return tmp\n",
    "\n",
    "# Convert to tensforflow dataset\n",
    "def convert_dict_to_tflow(d: dict) -> tf.data.Dataset:\n",
    "    return tf.data.Dataset.from_tensor_slices(d)\n",
    "\n",
    "        \n",
    "arrayed_user = values_to_array(user.dict())\n",
    "users = convert_dict_to_tflow(\n",
    "    concatenate_dicts([arrayed_user]*10000)\n",
    ")\n",
    "\n",
    "arrayed_rating = values_to_array(rating.flatten())\n",
    "ratings = convert_dict_to_tflow(\n",
    "    concatenate_dicts([arrayed_rating]*10000)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d410ca6",
   "metadata": {},
   "source": [
    "## Data Manipulation for Embedding\n",
    "We still need to generate embeddings for each tower.  We can use similar transformations as in the base tutorial for our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3109d2cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'restaurant_genres': array([1, 2, 3, 4]),\n",
      " 'restaurant_id': 1,\n",
      " 'restaurant_rating': 10,\n",
      " 'restaurant_title': b'skinnyfats',\n",
      " 'restaurant_zip_code': 84104,\n",
      " 'timestamp': 202201012200,\n",
      " 'user_birth_date': 20220101,\n",
      " 'user_gender': False,\n",
      " 'user_genres': array([1, 2]),\n",
      " 'user_id': 1001,\n",
      " 'user_occupation': b'student',\n",
      " 'user_zip_code': 84104}\n",
      "{'user_birth_date': 20220101,\n",
      " 'user_gender': False,\n",
      " 'user_genres': array([1, 2]),\n",
      " 'user_id': 1001,\n",
      " 'user_occupation': b'student',\n",
      " 'user_zip_code': 84104}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "for x in ratings.take(1).as_numpy_iterator():\n",
    "    pprint.pprint(x)\n",
    "for u in users.take(1).as_numpy_iterator():\n",
    "    pprint.pprint(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2424e859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map categorical features to embeddings for models\n",
    "\n",
    "def get_category_encoding_layer(name, dataset, dtype, max_tokens=None):\n",
    "    # Create a layer that turns strings into integer indices.\n",
    "    if dtype == 'string':\n",
    "        index = tf.keras.layers.StringLookup(max_tokens=max_tokens)\n",
    "        # Otherwise, create a layer that turns integer values into integer indices.\n",
    "    else:\n",
    "        index = tf.keras.layers.IntegerLookup(max_tokens=max_tokens)\n",
    "\n",
    "    # Prepare a `tf.data.Dataset` that only yields the feature.\n",
    "    feature_ds = dataset.map(lambda x: x[name])\n",
    "\n",
    "    # Learn the set of possible values and assign them a fixed integer index.\n",
    "    index.adapt(feature_ds)\n",
    "\n",
    "    # Encode the integer indices.\n",
    "    encoder = tf.keras.layers.CategoryEncoding(num_tokens=index.vocabulary_size())\n",
    "\n",
    "    # Apply multi-hot encoding to the indices. The lambda function captures the\n",
    "    # layer, so you can use them, or include them in the Keras Functional model later.\n",
    "    return lambda feature: encoder(index(feature))\n",
    "\n",
    "\n",
    "def get_text_tokenization_layer(name, dataset, max_features=1000, max_len=12):\n",
    "    # Prepare a `tf.data.Dataset` that only yields the feature.\n",
    "    feature_ds = dataset.map(lambda x: x[name])\n",
    "    \n",
    "    # Specify a vectorization layer\n",
    "    vectorize_layer = tf.keras.layers.TextVectorization(\n",
    "        max_tokens=max_features,\n",
    "        output_mode='int',\n",
    "        output_sequence_length=max_len)\n",
    "    \n",
    "    vectorize_layer.adapt(feature_ds.batch(64))\n",
    "    \n",
    "    # Create a model that can use the layer on the feature dataset\n",
    "    model = tf.keras.models.Sequential()\n",
    "    \n",
    "    # Explicit input layer\n",
    "    model.add(tf.keras.Input(shape=(1,), dtype=tf.string))\n",
    "    # vectorization layer\n",
    "    model.add(vectorize_layer)\n",
    "    \n",
    "    # Apply the model to indices\n",
    "    return lambda feature: model.predict(feature)\n",
    "\n",
    "    \n",
    "user_occ_layer = get_category_encoding_layer('user_occupation', users, 'string')\n",
    "rest_title_layer = get_text_tokenization_layer('restaurant_title', ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b9b74568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 94ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rest_title_layer(['text', 'test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b49d88fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding Layers\n",
    "embedding_dimension = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ec6136",
   "metadata": {},
   "source": [
    "### Query Tower\n",
    "\n",
    "Given a user (or set of users), yield embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad1c5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.StringLookup(\n",
    "        vocabulary=unique_occupations, mask_token=None),\n",
    "    tf.keras.layers.Embedding(len())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b8e70d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f352ef1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
