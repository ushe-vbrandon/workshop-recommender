{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d95160db",
   "metadata": {},
   "source": [
    "# Tensorflow Recommenders Tutorial\n",
    "https://www.tensorflow.org/recommenders/examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69ac670",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1255aa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "import tempfile\n",
    "\n",
    "from typing import Dict, Text\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91df73ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1149c776",
   "metadata": {},
   "source": [
    "## Preparing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd353ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to ~\\tensorflow_datasets\\movielens\\100k-ratings\\0.1.1...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6598e90e7c5749b3a93a2052701c21a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5828166ce8a4bd4b697b78c22bdd621",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e717aa461b74151bcc6d6eaecf6c15d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction completed...: 0 file [00:00, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4695b17b5d8a4646b66b026383b596b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/1 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1eedca210f64e87adad35e58c5d69c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "586758dfa57d44d88fe80bbce90866fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling ~\\tensorflow_datasets\\movielens\\100k-ratings\\0.1.1.incompleteX46MW0\\movielens-train.tfrecord*...:   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset movielens downloaded and prepared to ~\\tensorflow_datasets\\movielens\\100k-ratings\\0.1.1. Subsequent calls will reuse this data.\u001b[0m\n",
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to ~\\tensorflow_datasets\\movielens\\100k-movies\\0.1.1...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57af49e01cac4c82a454b35abba33c32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a64ed8cf3fb0484798879f2519c68ed0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9cf07a965194917b791c0dfe311e199",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction completed...: 0 file [00:00, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7a39cfc78fa4249afaa4f49184916bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/1 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0211d212092e4ebb855cc80d41a07e49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1595bf24ebd4abba639a994cc085827",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling ~\\tensorflow_datasets\\movielens\\100k-movies\\0.1.1.incomplete9FRSMR\\movielens-train.tfrecord*...:   0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset movielens downloaded and prepared to ~\\tensorflow_datasets\\movielens\\100k-movies\\0.1.1. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Ratings data.\n",
    "ratings = tfds.load(\"movielens/100k-ratings\", split=\"train\")\n",
    "# Features of all the available movies.\n",
    "movies = tfds.load(\"movielens/100k-movies\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1a2c21c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bucketized_user_age': 45.0,\n",
      " 'movie_genres': array([7], dtype=int64),\n",
      " 'movie_id': b'357',\n",
      " 'movie_title': b\"One Flew Over the Cuckoo's Nest (1975)\",\n",
      " 'raw_user_age': 46.0,\n",
      " 'timestamp': 879024327,\n",
      " 'user_gender': True,\n",
      " 'user_id': b'138',\n",
      " 'user_occupation_label': 4,\n",
      " 'user_occupation_text': b'doctor',\n",
      " 'user_rating': 4.0,\n",
      " 'user_zip_code': b'53211'}\n"
     ]
    }
   ],
   "source": [
    "# Examine a record\n",
    "\n",
    "## Note: the tensorflow dataset object has a unique API.  Slicing tensors to human-readable format can be tricky\n",
    "\n",
    "for x in ratings.take(1).as_numpy_iterator():\n",
    "    pprint.pprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1774561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'movie_genres': array([4], dtype=int64),\n",
      " 'movie_id': b'1681',\n",
      " 'movie_title': b'You So Crazy (1994)'}\n"
     ]
    }
   ],
   "source": [
    "for x in movies.take(1).as_numpy_iterator():\n",
    "    pprint.pprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fa41bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Reduction\n",
    "\n",
    "## We'll reduce features for the first model\n",
    "\n",
    "ratings = ratings.map(\n",
    "    lambda x: {\n",
    "        \"movie_title\": x[\"movie_title\"],\n",
    "        \"user_id\": x[\"user_id\"],\n",
    "    }\n",
    ")\n",
    "movies = movies.map(lambda x: x[\"movie_title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77b78ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Data Set into Training and Evaluation Chunks\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "shuffled = ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(80_000)\n",
    "test = shuffled.skip(80_000).take(20_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d052a0b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1664,\n",
       " array([b\"'Til There Was You (1997)\", b'1-900 (1994)',\n",
       "        b'101 Dalmatians (1996)', b'12 Angry Men (1957)', b'187 (1997)',\n",
       "        b'2 Days in the Valley (1996)',\n",
       "        b'20,000 Leagues Under the Sea (1954)',\n",
       "        b'2001: A Space Odyssey (1968)',\n",
       "        b'3 Ninjas: High Noon At Mega Mountain (1998)',\n",
       "        b'39 Steps, The (1935)'], dtype=object))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Map categorical features to embeddings for models\n",
    "\n",
    "movie_titles = movies.batch(1_000)\n",
    "user_ids = ratings.batch(1_000_000).map(lambda x: x[\"user_id\"])\n",
    "\n",
    "unique_movie_titles = np.unique(np.concatenate(list(movie_titles)))\n",
    "unique_user_ids = np.unique(np.concatenate(list(user_ids)))\n",
    "\n",
    "len(unique_movie_titles), unique_movie_titles[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2e4fca",
   "metadata": {},
   "source": [
    "# Implementing A Model\n",
    "\n",
    "Two-Tower Retrieval Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cc4773",
   "metadata": {},
   "source": [
    "### The Query Tower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b323e9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dimension = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23556402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing Layer to create user embeddings\n",
    "\n",
    "user_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.StringLookup(\n",
    "        vocabulary=unique_user_ids, mask_token=None),\n",
    "    # Add an additional embedding to account for unknown tokens\n",
    "    tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4adf6d8",
   "metadata": {},
   "source": [
    "### The Candidate Tower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "425490fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a similarly build embedding for movies\n",
    "\n",
    "movie_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.StringLookup(\n",
    "        vocabulary=unique_movie_titles, mask_token=None),\n",
    "    tf.keras.layers.Embedding(len(unique_movie_titles) + 1, embedding_dimension)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b6b9c828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x120cd892e20>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6e7e9f",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "\n",
    "Accuracy can be a trick to define in nearest neighbor models.  Here, we'll check the relative distance between positive pairs and all other candidates and hope the difference is high/relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0054db91",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = tfrs.metrics.FactorizedTopK(\n",
    "    candidates=movies.batch(128).map(movie_model)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c20bd7",
   "metadata": {},
   "source": [
    "## Loss\n",
    "\n",
    "We can use the metric (factorized top K) as a loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "31868431",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = tfrs.tasks.Retrieval(\n",
    "    metrics=metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b3e1f5",
   "metadata": {},
   "source": [
    "## The Full Model\n",
    "\n",
    "With the loss function and accuracy metric defined, data prepared, we can now define our full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "13daa283",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieLensModel(tfrs.Model):\n",
    "    \n",
    "    def __init__(self, user_model, movie_model):\n",
    "        super().__init__()\n",
    "        self.movie_model: tf.keras.Model = movie_model\n",
    "        self.user_model: tf.keras.Model = user_model\n",
    "        self.task: tf.keras.layers.Layer = task  # note task defined above\n",
    "            \n",
    "    def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "        # Pick out user features and feed to user model for user embeddings\n",
    "        user_embeddings = self.user_model(features[\"user_id\"])\n",
    "        # Pick out movie features to get movie embeddings\n",
    "        positive_movie_embeddings = self.movie_model(features[\"movie_title\"])\n",
    "        \n",
    "        # Calculate loss and metrics, return\n",
    "        return self.task(user_embeddings, positive_movie_embeddings)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a0140e",
   "metadata": {},
   "source": [
    "## Fit and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "202c085d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MovieLensModel(user_model=user_model, movie_model=movie_model)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "557bc824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle, batch, cache training/eval data\n",
    "cached_train = train.shuffle(100_000).batch(8192).cache()\n",
    "cached_test = test.batch(4096).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "90d553aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "10/10 [==============================] - 12s 943ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0012 - factorized_top_k/top_5_categorical_accuracy: 0.0098 - factorized_top_k/top_10_categorical_accuracy: 0.0206 - factorized_top_k/top_50_categorical_accuracy: 0.1005 - factorized_top_k/top_100_categorical_accuracy: 0.1775 - loss: 69885.1108 - regularization_loss: 0.0000e+00 - total_loss: 69885.1108\n",
      "Epoch 2/3\n",
      "10/10 [==============================] - 9s 948ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0027 - factorized_top_k/top_5_categorical_accuracy: 0.0190 - factorized_top_k/top_10_categorical_accuracy: 0.0381 - factorized_top_k/top_50_categorical_accuracy: 0.1697 - factorized_top_k/top_100_categorical_accuracy: 0.2930 - loss: 67523.3679 - regularization_loss: 0.0000e+00 - total_loss: 67523.3679\n",
      "Epoch 3/3\n",
      "10/10 [==============================] - 11s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.0036 - factorized_top_k/top_5_categorical_accuracy: 0.0228 - factorized_top_k/top_10_categorical_accuracy: 0.0459 - factorized_top_k/top_50_categorical_accuracy: 0.1883 - factorized_top_k/top_100_categorical_accuracy: 0.3163 - loss: 66302.9560 - regularization_loss: 0.0000e+00 - total_loss: 66302.9560\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x120cd8436a0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "model.fit(cached_train, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a2aef633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 312ms/step - factorized_top_k/top_1_categorical_accuracy: 9.5000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0094 - factorized_top_k/top_10_categorical_accuracy: 0.0227 - factorized_top_k/top_50_categorical_accuracy: 0.1247 - factorized_top_k/top_100_categorical_accuracy: 0.2326 - loss: 31079.0641 - regularization_loss: 0.0000e+00 - total_loss: 31079.0641\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'factorized_top_k/top_1_categorical_accuracy': 0.0009500000160187483,\n",
       " 'factorized_top_k/top_5_categorical_accuracy': 0.009399999864399433,\n",
       " 'factorized_top_k/top_10_categorical_accuracy': 0.022749999538064003,\n",
       " 'factorized_top_k/top_50_categorical_accuracy': 0.1246500015258789,\n",
       " 'factorized_top_k/top_100_categorical_accuracy': 0.2326499968767166,\n",
       " 'loss': 28244.7734375,\n",
       " 'regularization_loss': 0,\n",
       " 'total_loss': 28244.7734375}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate Model\n",
    "model.evaluate(cached_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cbc67d",
   "metadata": {},
   "source": [
    "## Making Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "695ae695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reccommendations for user 42: [b'Bridges of Madison County, The (1995)'\n",
      " b'Father of the Bride Part II (1995)' b'Rudy (1993)'])\n"
     ]
    }
   ],
   "source": [
    "# Create a model thiat takes in raw query features, and\n",
    "index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
    "# recommends movies out of the entire movies dataset\n",
    "index.index_from_dataset(\n",
    "    tf.data.Dataset.zip((movies.batch(100), movies.batch(100).map(model.movie_model)))\n",
    ")\n",
    "\n",
    "# Get recommendations.\n",
    "_, titles = index(tf.constant([\"42\"]))\n",
    "print(f\"Reccommendations for user 42: {titles[0, :3]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9a488a",
   "metadata": {},
   "source": [
    "## Exporting the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f4c9c24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as query_with_exclusions while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\u1377381\\AppData\\Local\\Temp\\tmpbrfxyoiz\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\u1377381\\AppData\\Local\\Temp\\tmpbrfxyoiz\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reccommendations for user 42: [[b'Deep Rising (1998)' b'Truman Show, The (1998)' b'Mimic (1997)']\n",
      " [b'Mimic (1997)' b'Money Talks (1997)' b'Money Talks (1997)']\n",
      " [b'Bridges of Madison County, The (1995)'\n",
      "  b'Father of the Bride Part II (1995)' b'Rudy (1993)']])\n"
     ]
    }
   ],
   "source": [
    "# Export the query model\n",
    "with tempfile.TemporaryDirectory() as tmp:\n",
    "    path = os.path.join(tmp, \"model\")\n",
    "    \n",
    "    # save the index\n",
    "    tf.saved_model.save(index, path)\n",
    "    \n",
    "    # load it back; can also be done via TensorFlow Serving\n",
    "    loaded = tf.saved_model.load(path)\n",
    "    \n",
    "    # Pass a user id in, get top predicted movies back\n",
    "    scores, titles = loaded([\"3\", \"4\", \"42\"])\n",
    "    \n",
    "    print(f\"Reccommendations for user 42: {titles[:3, :3]})\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9cabd2",
   "metadata": {},
   "source": [
    "## Fine Tuning Candidates with Ranking\n",
    "\n",
    "The candidate retrieval, indexing, step yielded a items in a region around the search query.  To order them by predicted preference, we'll also implement a ranking model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8a1bd698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload ratings data (can use same features for both, but check query input dim)\n",
    "\n",
    "ratings = tfds.load(\"movielens/100k-ratings\", split=\"train\")\n",
    "\n",
    "ratings = ratings.map(lambda x: {\n",
    "    \"movie_title\": x[\"movie_title\"],\n",
    "    \"user_id\": x[\"user_id\"],\n",
    "    \"user_rating\": x[\"user_rating\"]\n",
    "})\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "shuffled = ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(80_000)\n",
    "test = shuffled.skip(80_000).take(20_000)\n",
    "\n",
    "movie_titles = ratings.batch(1_000_000).map(lambda x: x[\"movie_title\"])\n",
    "user_ids = ratings.batch(1_000_000).map(lambda x: x[\"user_id\"])\n",
    "\n",
    "unique_movie_titles = np.unique(np.concatenate(list(movie_titles)))\n",
    "unique_user_ids = np.unique(np.concatenate(list(user_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "27ecf269",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RankingModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        embedding_dimension = 32\n",
    "\n",
    "        # Compute embeddings for users.\n",
    "        self.user_embeddings = tf.keras.Sequential([\n",
    "          tf.keras.layers.StringLookup(\n",
    "            vocabulary=unique_user_ids, mask_token=None),\n",
    "          tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
    "        ])\n",
    "\n",
    "        # Compute embeddings for movies.\n",
    "        self.movie_embeddings = tf.keras.Sequential([\n",
    "          tf.keras.layers.StringLookup(\n",
    "            vocabulary=unique_movie_titles, mask_token=None),\n",
    "          tf.keras.layers.Embedding(len(unique_movie_titles) + 1, embedding_dimension)\n",
    "        ])\n",
    "\n",
    "        # Compute predictions.\n",
    "        self.ratings = tf.keras.Sequential([\n",
    "          # Learn multiple dense layers.\n",
    "          tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "          tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "          # Make rating predictions in the final layer.\n",
    "          tf.keras.layers.Dense(1)\n",
    "        ])\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        user_id, movie_title = inputs\n",
    "\n",
    "        user_embedding = self.user_embeddings(user_id)\n",
    "        movie_embedding = self.movie_embeddings(movie_title)\n",
    "\n",
    "        return self.ratings(tf.concat([user_embedding, movie_embedding], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d6498e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=['42']. Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=['42']. Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=[\"One Flew Over the Cuckoo's Nest (1975)\"]. Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=[\"One Flew Over the Cuckoo's Nest (1975)\"]. Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.03740937]], dtype=float32)>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RankingModel()(([\"42\"], [\"One Flew Over the Cuckoo's Nest (1975)\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8ed7b762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New loss function for ranking model\n",
    "task = tfrs.tasks.Ranking(\n",
    "  loss = tf.keras.losses.MeanSquaredError(),\n",
    "  metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b269296d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rewrite MovieLens Model for ranking\n",
    "class MovielensRankingModel(tfrs.models.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.ranking_model: tf.keras.Model = RankingModel()\n",
    "        self.task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
    "          loss = tf.keras.losses.MeanSquaredError(),\n",
    "          metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    "        )\n",
    "\n",
    "    def call(self, features: Dict[str, tf.Tensor]) -> tf.Tensor:\n",
    "        return self.ranking_model(\n",
    "            (features[\"user_id\"], features[\"movie_title\"]))\n",
    "\n",
    "    def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "        labels = features.pop(\"user_rating\")\n",
    "\n",
    "        rating_predictions = self(features)\n",
    "\n",
    "        # The task computes the loss and the metrics.\n",
    "        return self.task(labels=labels, predictions=rating_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ace6aa66",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MovielensRankingModel()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2a6a5b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_train = train.shuffle(100_000).batch(8192).cache()\n",
    "cached_test = test.batch(4096).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a6e6858f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10/10 [==============================] - 2s 37ms/step - root_mean_squared_error: 2.1718 - loss: 4.3303 - regularization_loss: 0.0000e+00 - total_loss: 4.3303\n",
      "Epoch 2/5\n",
      "10/10 [==============================] - 0s 28ms/step - root_mean_squared_error: 1.1227 - loss: 1.2602 - regularization_loss: 0.0000e+00 - total_loss: 1.2602\n",
      "Epoch 3/5\n",
      "10/10 [==============================] - 0s 26ms/step - root_mean_squared_error: 1.1162 - loss: 1.2456 - regularization_loss: 0.0000e+00 - total_loss: 1.2456\n",
      "Epoch 4/5\n",
      "10/10 [==============================] - 0s 24ms/step - root_mean_squared_error: 1.1073 - loss: 1.2252 - regularization_loss: 0.0000e+00 - total_loss: 1.2252\n",
      "Epoch 5/5\n",
      "10/10 [==============================] - 0s 22ms/step - root_mean_squared_error: 1.0935 - loss: 1.1942 - regularization_loss: 0.0000e+00 - total_loss: 1.1942\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12084a27340>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(cached_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c9112857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 13ms/step - root_mean_squared_error: 1.0836 - loss: 1.1699 - regularization_loss: 0.0000e+00 - total_loss: 1.1699\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'root_mean_squared_error': 1.0835518836975098,\n",
       " 'loss': 1.1517865657806396,\n",
       " 'regularization_loss': 0,\n",
       " 'total_loss': 1.1517865657806396}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(cached_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "698bd5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings:\n",
      "M*A*S*H (1970): [[3.6522346]]\n",
      "Dances with Wolves (1990): [[3.5988433]]\n",
      "Speed (1994): [[3.5449886]]\n"
     ]
    }
   ],
   "source": [
    "test_ratings = {}\n",
    "test_movie_titles = [\"M*A*S*H (1970)\", \"Dances with Wolves (1990)\", \"Speed (1994)\"]\n",
    "for movie_title in test_movie_titles:\n",
    "    test_ratings[movie_title] = model({\n",
    "      \"user_id\": np.array([\"42\"]),\n",
    "      \"movie_title\": np.array([movie_title])\n",
    "    })\n",
    "\n",
    "print(\"Ratings:\")\n",
    "for title, score in sorted(test_ratings.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{title}: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6a45d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
